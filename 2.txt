!pip install pypdf pandas

import os
import re
import pandas as pd
from datetime import datetime
from google.colab import drive
from pypdf import PdfReader

# Mount Google Drive
drive.mount('/content/drive')

import time
start = time.time()

# Base directory for PDFs
base_dir = "/content/drive/My Drive/Colab Notebooks/20250716_CR data/docs/Companies Ordinance pdfs"

# Lists to store DataFrames
all_dfs = []  # For main table data
summary_data = []  # For summary table

# Function to check if PDF contains the phrase and extract text per page
def contains_phrase(pdf_path):
    try:
        with open(pdf_path, 'rb') as file:
            reader = PdfReader(file)
            pages_text = []
            sections_found = set()
            for page in reader.pages:
                page_text = page.extract_text()
                if page_text:
                    # Check for 'struck\s*off' or 'deregister'
                    if re.search(r'struck\s*off|deregister', page_text, re.IGNORECASE):
                        # Remove spaces for section pattern matching
                        text_no_spaces = ''.join(page_text.split())
                        # Find section pattern like section{number}...) within 10 chars of 'section'
                        section_match = re.search(r'section\d+\([^)]{0,10}\)', text_no_spaces, re.IGNORECASE)
                        if section_match:
                            sections_found.add(section_match.group(0))
                    pages_text.append(page_text)
            has_phrase = bool(sections_found)
            return has_phrase, pages_text, list(sections_found) if sections_found else ['None']
    except Exception as e:
        print(f"Error reading {pdf_path}: {e}")
        return False, [], ['None']

# Function to extract table using regex after 'afterthedatehereof' for each page
def extract_table_regex(pages_text, folder_date, gn_number, sections_found):
    try:
        dfs = []
        total_rows = 0
        unique_cis = set()

        for page_text in pages_text:
            # Find text after 'afterthedatehereof' in this page
            match = re.search(r'afterthedatehereof', page_text, re.IGNORECASE)
            if match:
                page_text = page_text[match.end():]  # Extract text after the phrase
            else:
                # If phrase not found, process the entire page text
                pass

            # Pattern to match rows like "66139473, ACERAS (HK) TECHNOLOGY CO., LIMITED, 阿格瑞斯(香港)科技有限公司"
            pattern = r'\b(\d{6,9})\b\s*[,|\s]+([^\u4e00-\u9fff]+?)(?:[,|\s]+([\u4e00-\u9fff\(\)]+)|(?<!\S)(?:\S{0,3}(?![\u4e00-\u9fff])))?(?=\s*\n|\s*$)'
            matches = re.findall(pattern, page_text, re.MULTILINE)

            if matches:
                # Create DataFrame from matches
                df = pd.DataFrame(matches, columns=['CI', 'ENGLISH_NAME', 'CHINESE_NAME'])
                # Clean up columns
                df['CI'] = df['CI'].str.strip()
                df['ENGLISH_NAME'] = df['ENGLISH_NAME'].str.strip()
                df['CHINESE_NAME'] = df['CHINESE_NAME'].str.strip().replace('公司註冊處處長', '', regex=False).fillna('')
                # Add PUBLISHED_DATE, GOV_NOTICE_NUM, and SECTION
                df['PUBLISHED_DATE'] = datetime.strptime(folder_date, '%Y%m%d').strftime('%Y-%m-%d')
                df['GOV_NOTICE_NUM'] = gn_number
                df['SECTION'] = ', '.join(sections_found)  # Combine all sections found
                dfs.append(df)
                total_rows += len(df)
                unique_cis.update(df['CI'])

        if dfs:
            combined_df = pd.concat(dfs, ignore_index=True)
            return combined_df, total_rows, len(unique_cis)
        return None, 0, 0
    except Exception as e:
        print(f"Error in regex extraction: {e}")
        return None, 0, 0

# Iterate through folders
for folder_name in os.listdir(base_dir):
    folder_path = os.path.join(base_dir, folder_name)
    if os.path.isdir(folder_path) and re.match(r'\d{8}', folder_name):  # Validate folder name (yyyymmdd)
        for filename in os.listdir(folder_path):
            if filename.startswith('GN_') and filename.endswith('.pdf'):
                gn_number = filename.replace('GN_', '').replace('.pdf', '')
                pdf_path = os.path.join(folder_path, filename)
                print(f"Checking PDF: {pdf_path}")

                # Check for phrase and get text per page
                has_phrase, pages_text, sections_found = contains_phrase(pdf_path)

                # Add to summary with PUBLISHED_DATE and GOV_NOTICE_NUM
                summary_entry = {
                    'Publish Date': datetime.strptime(folder_name, '%Y%m%d').strftime('%Y-%m-%d'),
                    'GN Number': gn_number,
                    'Passed contains_phrase': has_phrase,
                    'Passed extract_table_regex': True,  # Always True since only regex is used
                    'Mapping Method': 'PdfReader' if has_phrase else 'None',
                    'Mapped Cnt': 0,
                    'Mapped Distinct Count': 0,
                    'Section': ', '.join(sections_found),
                    'Item Screened': pdf_path
                }

                if has_phrase:
                    df, row_count, unique_ci_count = extract_table_regex(pages_text, folder_name, gn_number, sections_found)
                    if df is not None:
                        all_dfs.append(df)
                        summary_entry['Mapped Cnt'] = row_count
                        summary_entry['Mapped Distinct Cnt'] = unique_ci_count

                summary_data.append(summary_entry)


# Combine main DataFrame
if all_dfs:
    main_df = pd.concat(all_dfs, ignore_index=True)
    # Sort by PUBLISHED_DATE and GOV_NOTICE_NUM
    main_df = main_df.sort_values(by=['PUBLISHED_DATE', 'GOV_NOTICE_NUM'])
    print("\nExtracted Tables from PDFs:")
    # print(main_df.to_string(index=False))
else:
    print("\nNo tables extracted from PDFs.")

# Create and print summary DataFrame
summary_df = pd.DataFrame(summary_data)
summary_df = summary_df.sort_values(by=['Item Screened'])
print("\nSummary of PDF Processing:")
# print(summary_df.to_string(index=False))

output_dir = '/content/drive/My Drive/Colab Notebooks/20250716_CR data/output'

main_df.to_excel(f'{output_dir}/main_output.xlsx', sheet_name='Sheet1', index=False, engine='openpyxl')
summary_df.to_excel(f'{output_dir}/summary_df.xlsx', sheet_name='Sheet1', index=False, engine='openpyxl')
print('Done.')
end = time.time()
print((end-start)/60)
